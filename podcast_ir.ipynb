{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333ae546d607a744",
   "metadata": {},
   "source": [
    "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
    "\n",
    "## Objective:\n",
    "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a934919d95ac2de",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "* Follow the steps outlined above to implement the IR system.\n",
    "* Run the provided code snippets to understand how each part of the system works.\n",
    "* Test the system with various queries to observe the results from both TF-IDF and BERT representations.\n",
    "* Compare and analyze the results. Discuss the pros and cons of each method.\n",
    "* Document your findings and any improvements you make to the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134bbb7-a5d5-4a1b-be5e-8bac4a3ef268",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Step 1: Import Libraries\n",
    "Import necessary libraries for data handling, text processing, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eec47525-279c-4e30-bead-c2ede3ad34ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USUARIO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USUARIO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e486a3-d6aa-44f9-a435-63066a3838bb",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset\n",
    "\n",
    "Load the dataset of podcast transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f433392-872b-4872-b244-4fd7d66dafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the local file\n",
    "podcast_data = pd.read_csv('podcastdata_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc4057-4d33-4b65-a02a-7f40fbfc45d7",
   "metadata": {},
   "source": [
    "### Step 3: Text Preprocessing\n",
    "\n",
    "You know what to do ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db437c7c-41fb-4083-b9ca-a6923bc124c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove whitespace\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [w for w in word_tokens if not w in stop_words]\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "podcast_data['cleaned_text'] = podcast_data['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591518ae-53c7-4a79-a2b3-287d85e5ad59",
   "metadata": {},
   "source": [
    "###  Step 4: Vector Space Representation - TF-IDF\n",
    "\n",
    "Create TF-IDF vector representations of the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80a6218-062f-45a8-b7b9-2bb6ae0916b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vector representations\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(podcast_data['cleaned_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33bf05-c54c-4930-abe9-21b0c791a1ed",
   "metadata": {},
   "source": [
    "### Step 5: Vector Space Representation - BERT\n",
    "\n",
    "Create BERT vector representations of the transcripts using a pre-trained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ebcb547-85ec-49e7-bb7d-4c12d9357408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def embed_bert(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "\n",
    "# Create BERT vector representations\n",
    "bert_embeddings = np.array([embed_bert(text) for text in podcast_data['cleaned_text']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a8ff29-6c03-4a65-b4bf-e0b17a3e7695",
   "metadata": {},
   "source": [
    "### Step 6: Query Processing\n",
    "\n",
    "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0846dd7b-a162-4b7c-a828-5956ac4092f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the query with the preprocess function\n",
    "def process_query(query, vectorizer, tfidf_matrix, bert_model, bert_tokenizer):\n",
    "    query_cleaned = preprocess_text(query)\n",
    "    \n",
    "    # TF-IDF\n",
    "    query_tfidf = vectorizer.transform([query_cleaned])\n",
    "    tfidf_scores = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "    \n",
    "    # BERT\n",
    "    query_bert = embed_bert(query_cleaned)\n",
    "    bert_scores = cosine_similarity([query_bert], bert_embeddings).flatten()\n",
    "    \n",
    "    return tfidf_scores, bert_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95a4ee-3255-483e-8cce-fd892d7c88bc",
   "metadata": {},
   "source": [
    "### Step 7: Retrieve and Compare Results\n",
    "\n",
    "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1360654-df49-4e54-b738-48d404ac6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve the first 5 relevant results\n",
    "def retrieve_top_results(scores, podcast_data, top_n=5):\n",
    "    top_indices = np.argsort(scores)[::-1][:top_n]\n",
    "    top_results = podcast_data.iloc[top_indices]\n",
    "    return top_results\n",
    "#Display the results of TF-IDF and BERT \n",
    "def display_results(results, method):\n",
    "    print(f\"Top results using {method}:\")\n",
    "    for i, row in results.iterrows():\n",
    "        print(f\"Episode ID: {row['id']}, Guest: {row['guest']}, Title: {row['title']}\")\n",
    "        print(f\"Transcript: {row['text'][:100]}...\")  # Display the first 100 characters\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c415b32-5144-4e83-8b7a-c3d4eee69685",
   "metadata": {},
   "source": [
    "### Step 8: Test the IR System\n",
    "\n",
    "Test the system with a sample query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da60f89-0a3e-4827-8435-11175ff88ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results using TF-IDF:\n",
      "Episode ID: 3, Guest: Steven Pinker, Title: AI in the Age of Reason\n",
      "Transcript: You've studied the human mind, cognition, language, vision, evolution, psychology, from child to adu...\n",
      "\n",
      "Episode ID: 61, Guest: Melanie Mitchell, Title: Concepts, Analogies, Common Sense & Future of AI\n",
      "Transcript: The following is a conversation with Melanie Mitchell. She's a professor of computer science at Port...\n",
      "\n",
      "Episode ID: 120, Guest: François Chollet, Title: Measures of Intelligence\n",
      "Transcript: The following is a conversation with Francois Chollet, his second time on the podcast. He's both a w...\n",
      "\n",
      "Episode ID: 38, Guest: François Chollet, Title: Keras, Deep Learning, and the Progress of AI\n",
      "Transcript: The following is a conversation with Francois Chollet. He's the creator of Keras, which is an open s...\n",
      "\n",
      "Episode ID: 302, Guest: Richard Haier, Title: IQ Tests, Human Intelligence, and Group Differences\n",
      "Transcript: Let me ask you to this question, whether it's bell curve or any research on race differences, can th...\n",
      "\n",
      "Top results using BERT:\n",
      "Episode ID: 177, Guest: Risto Miikkulainen, Title: Neuroevolution and Evolutionary Computation\n",
      "Transcript: The following is a conversation with Risto Michaelainen, a computer scientist at University of Texas...\n",
      "\n",
      "Episode ID: 61, Guest: Melanie Mitchell, Title: Concepts, Analogies, Common Sense & Future of AI\n",
      "Transcript: The following is a conversation with Melanie Mitchell. She's a professor of computer science at Port...\n",
      "\n",
      "Episode ID: 90, Guest: Dmitry Korkin, Title: Computational Biology of Coronavirus\n",
      "Transcript: The following is a conversation with Dmitry Korkin. He's a professor of bioinformatics and computati...\n",
      "\n",
      "Episode ID: 43, Guest: Gary Marcus, Title: Toward a Hybrid of Deep Learning and Symbolic AI\n",
      "Transcript: The following is a conversation with Gary Marcus. He's a professor emeritus at NYU, founder of Robus...\n",
      "\n",
      "Episode ID: 38, Guest: François Chollet, Title: Keras, Deep Learning, and the Progress of AI\n",
      "Transcript: The following is a conversation with Francois Chollet. He's the creator of Keras, which is an open s...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Artificial Intelligence\"\n",
    "tfidf_scores, bert_scores = process_query(query, tfidf_vectorizer, tfidf_matrix, model, tokenizer)\n",
    "\n",
    "# Retrieve and display the top results\n",
    "tfidf_results = retrieve_top_results(tfidf_scores, podcast_data)\n",
    "bert_results = retrieve_top_results(bert_scores, podcast_data)\n",
    "\n",
    "display_results(tfidf_results, \"TF-IDF\")\n",
    "display_results(bert_results, \"BERT\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eaa7e5-454b-43da-96c7-70ec39bfa763",
   "metadata": {},
   "source": [
    "### Step 9: Compare Results\n",
    "\n",
    "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
    "\n",
    "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bf5c710-c6f5-4288-b870-302e9073cfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Results:\n",
      "Top results using TF-IDF:\n",
      "Episode ID: 3, Guest: Steven Pinker, Title: AI in the Age of Reason\n",
      "Transcript: You've studied the human mind, cognition, language, vision, evolution, psychology, from child to adu...\n",
      "\n",
      "Episode ID: 61, Guest: Melanie Mitchell, Title: Concepts, Analogies, Common Sense & Future of AI\n",
      "Transcript: The following is a conversation with Melanie Mitchell. She's a professor of computer science at Port...\n",
      "\n",
      "Episode ID: 120, Guest: François Chollet, Title: Measures of Intelligence\n",
      "Transcript: The following is a conversation with Francois Chollet, his second time on the podcast. He's both a w...\n",
      "\n",
      "Episode ID: 38, Guest: François Chollet, Title: Keras, Deep Learning, and the Progress of AI\n",
      "Transcript: The following is a conversation with Francois Chollet. He's the creator of Keras, which is an open s...\n",
      "\n",
      "Episode ID: 302, Guest: Richard Haier, Title: IQ Tests, Human Intelligence, and Group Differences\n",
      "Transcript: Let me ask you to this question, whether it's bell curve or any research on race differences, can th...\n",
      "\n",
      "\n",
      "BERT Results:\n",
      "Top results using BERT:\n",
      "Episode ID: 177, Guest: Risto Miikkulainen, Title: Neuroevolution and Evolutionary Computation\n",
      "Transcript: The following is a conversation with Risto Michaelainen, a computer scientist at University of Texas...\n",
      "\n",
      "Episode ID: 61, Guest: Melanie Mitchell, Title: Concepts, Analogies, Common Sense & Future of AI\n",
      "Transcript: The following is a conversation with Melanie Mitchell. She's a professor of computer science at Port...\n",
      "\n",
      "Episode ID: 90, Guest: Dmitry Korkin, Title: Computational Biology of Coronavirus\n",
      "Transcript: The following is a conversation with Dmitry Korkin. He's a professor of bioinformatics and computati...\n",
      "\n",
      "Episode ID: 43, Guest: Gary Marcus, Title: Toward a Hybrid of Deep Learning and Symbolic AI\n",
      "Transcript: The following is a conversation with Gary Marcus. He's a professor emeritus at NYU, founder of Robus...\n",
      "\n",
      "Episode ID: 38, Guest: François Chollet, Title: Keras, Deep Learning, and the Progress of AI\n",
      "Transcript: The following is a conversation with Francois Chollet. He's the creator of Keras, which is an open s...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze and compare the results\n",
    "def compare_results(tfidf_results, bert_results):\n",
    "    print(\"TF-IDF Results:\")\n",
    "    display_results(tfidf_results, \"TF-IDF\")\n",
    "    print(\"\\nBERT Results:\")\n",
    "    display_results(bert_results, \"BERT\")\n",
    "\n",
    "compare_results(tfidf_results, bert_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2d944-20b0-4a16-8852-6e2e8fe58946",
   "metadata": {},
   "source": [
    "### Discuss the differences, strengths, and weaknesses of each method based on the retrieval results\n",
    "- **TF-IDF:**\n",
    "  - **Strengths:**\n",
    "    - Generally faster and easier to implement.\n",
    "    - Requires less computational resources compared to BERT.\n",
    "  - **Weaknesses:**\n",
    "    - May not capture semantic meaning as effectively as BERT.\n",
    "    - Relies heavily on term frequency, which might miss contextual nuances.\n",
    "\n",
    "- **BERT:**\n",
    "  - **Strengths:**\n",
    "    - Can capture more complex semantic relationships.\n",
    "    - Understands context better due to its deep learning architecture.\n",
    "  - **Weaknesses:**\n",
    "    - Computationally expensive and requires more resources.\n",
    "    - Slower to process compared to TF-IDF, especially for large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46650907-a2c7-419d-b43b-eec29f8fc45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
