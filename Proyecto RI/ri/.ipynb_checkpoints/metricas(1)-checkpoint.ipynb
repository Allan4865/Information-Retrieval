{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013e01a5-bd5c-4e9e-860a-e25e696339cb",
   "metadata": {},
   "source": [
    "# 1. Introducción\n",
    "\n",
    "El objetivo de este proyecto es diseñar, construir, programar y desplegar un Sistema de Recuperación de Información (SRI) utilizando el corpus Reuters-21578. El proyecto se dividirá en varias fases, que se describen a continuación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3522d281-6674-449c-9aca-73e9f5bff9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335d08f1-4993-466b-bf04-38d3ed8e0981",
   "metadata": {},
   "source": [
    "# 2. Fases del Proyecto\n",
    "\n",
    "## 2.1. Adquisición de Datos\n",
    "\n",
    "**Objetivo:** Obtener y preparar el corpus Reuters-21578.\n",
    "\n",
    "**Tareas:**\n",
    "- Descargar el corpus Reuters-21578.\n",
    "- Descomprimir y organizar los archivos.\n",
    "- Documentar el proceso de adquisición de datos.\n",
    "\n",
    "## 2.2. Preprocesamiento\n",
    "\n",
    "**Objetivo:** Limpiar y preparar los datos para su análisis.\n",
    "\n",
    "**Tareas:**\n",
    "- Extraer el contenido relevante de los documentos.\n",
    "- Realizar limpieza de datos: eliminación de caracteres no deseados, normalización de texto, etc.\n",
    "- Tokenización: dividir el texto en palabras o tokens.\n",
    "- Eliminar stop words y aplicar stemming o lematización.\n",
    "- Documentar cada paso del preprocesamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102fe1f-dc74-4ecb-ba89-a6a863c6c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la ruta del corpus y las stopwords en tu sistema local\n",
    "CORPUS_PATH = \"reuters/training\"\n",
    "STOPWORDS_PATH = \"reuters/stopwords\"\n",
    "BOW_INDEX_PATH = \"reuters/bow/indice_invertido_bow.txt\"\n",
    "TFIDF_INDEX_PATH = \"reuters/tf_idf/indice_invertido_tf_idf.txt\"\n",
    "\n",
    "# Leer las stopwords desde el archivo\n",
    "with open(STOPWORDS_PATH, 'r', encoding='ascii') as file:\n",
    "    stop_words = set(word.strip() for word in file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e802a-2488-4dee-abe0-3fc77ab7a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de preprocesamiento\n",
    "def lmp(texto):\n",
    "  #Normalización\n",
    "  cleaned_text = re.sub(r'[^\\w\\s]', '', texto)\n",
    "  cleaned_text = cleaned_text.lower()\n",
    "  words = cleaned_text.split()\n",
    " # Steaming\n",
    "  stemmer = PorterStemmer()\n",
    "  stemmed_words = [stemmer.stem(word) for word in words]\n",
    "# Eliminar stopwords\n",
    "  filtered_words = [word for word in stemmed_words if word not in stop_words]\n",
    "  cleaned_text = ' '.join(filtered_words)\n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ecd99-993b-474f-824c-1cfcac317f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer y preprocesar documentos del corpus\n",
    "documentos = {}\n",
    "for filename in os.listdir(CORPUS_PATH):\n",
    "    filepath = os.path.join(CORPUS_PATH, filename)\n",
    "    with open(filepath, 'r', encoding='ascii') as file:\n",
    "        text = file.read()\n",
    "        cleaned_text = lmp(text)\n",
    "        documentos[filename] = cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997e7866-8bbe-4f5d-b604-c9f2490397bd",
   "metadata": {},
   "source": [
    "## 2.3. Representación de Datos en Espacio Vectorial\n",
    "\n",
    "**Objetivo:** Convertir los textos en una forma que los algoritmos puedan procesar.\n",
    "\n",
    "**Tareas:**\n",
    "- Utilizar técnicas como Bag of Words (BoW) y TF-IDF para vectorizar el texto.\n",
    "- Evaluar las diferentes técnicas de vectorización.\n",
    "- Documentar los métodos y resultados obtenidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e231919-3e49-4868-937c-52eec7ec19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorización Bag of Words\n",
    "corpus = list(documentos.values())\n",
    "vectorizer_bow = CountVectorizer()\n",
    "X_bow = vectorizer_bow.fit_transform(corpus)\n",
    "df_bow = pd.DataFrame(X_bow.toarray(), columns=vectorizer_bow.get_feature_names_out(), index=documentos.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068da3f8-f06a-47ee-a674-17a2f0dfc798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorización TF-IDF\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(corpus)\n",
    "df_tf_idf = pd.DataFrame(X_tfidf.toarray(), columns=vectorizer_tfidf.get_feature_names_out(), index=documentos.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93577d28-1527-4339-9472-cdf5c6f92df4",
   "metadata": {},
   "source": [
    "## 2.4. Indexación\n",
    "\n",
    "**Objetivo:** Crear un índice que permita búsquedas eficientes.\n",
    "\n",
    "**Tareas:**\n",
    "- Construir un índice invertido que mapee términos a documentos.\n",
    "- Implementar y optimizar estructuras de datos para el índice.\n",
    "- Documentar el proceso de construcción del índice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d678a0dd-ba30-4701-9d69-029aa22e12aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inverted_index_from_txt(filepath):\n",
    "    inverted_index = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        current_term = None\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"Termino:\"):\n",
    "                current_term = line.split(\"Termino: \")[1]\n",
    "                inverted_index[current_term] = []\n",
    "            elif line.startswith(\"Documento:\"):\n",
    "                doc_info = line.split(\"Documento: \")[1]\n",
    "                doc_name, weight = doc_info.split(\", Frecuencia: \")\n",
    "                inverted_index[current_term].append((doc_name, float(weight)))\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c715c-71eb-4c8b-8cee-2d530f8b9063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar índices invertidos desde archivos de texto\n",
    "inverted_index_bow_loaded = load_inverted_index_from_txt(BOW_INDEX_PATH)\n",
    "inverted_index_tfidf_loaded = load_inverted_index_from_txt(TFIDF_INDEX_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b90509-9cea-4798-aa5b-d3787e911630",
   "metadata": {},
   "source": [
    "## 2.5. Diseño del Motor de Búsqueda\n",
    "\n",
    "**Objetivo:** Implementar la funcionalidad de búsqueda.\n",
    "\n",
    "**Tareas:**\n",
    "- Desarrollar la lógica para procesar consultas de usuarios.\n",
    "- Implementar algoritmos de similitud como similitud coseno o Jaccard.\n",
    "- Desarrollar un algoritmo de ranking para ordenar los resultados.\n",
    "- Documentar la arquitectura y los algoritmos utilizados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebddfa8-e6af-41a7-9298-f77d888f291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de búsqueda\n",
    "def process_query(query):\n",
    "    cleaned_query = lmp(query)\n",
    "    return cleaned_query.split()\n",
    "\n",
    "def jaccard_similarity(query_tokens, document_tokens):\n",
    "    intersection = len(set(query_tokens) & set(document_tokens))\n",
    "    union = len(set(query_tokens) | set(document_tokens))\n",
    "    return intersection / union if union != 0 else 0  # Avoid division by zero\n",
    "\n",
    "def cosine_similarity_score(vector1, vector2):\n",
    "    return cosine_similarity([vector1], [vector2])[0][0]\n",
    "\n",
    "def search_with_bow(query, inverted_index_bow, documents):\n",
    "    query_tokens = process_query(query)\n",
    "    doc_tokens = {doc_id: documentos[doc_id].split() for doc_id in documentos}\n",
    "    scores = {}\n",
    "    for doc_id in doc_tokens:\n",
    "        scores[doc_id] = jaccard_similarity(query_tokens, doc_tokens[doc_id])\n",
    "    ranked_results = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return ranked_results\n",
    "\n",
    "def search_with_tfidf(query, tfidf_matrix, vectorizer_tfidf, documents):\n",
    "    query_tokens = process_query(query)\n",
    "    query_vector = vectorizer_tfidf.transform([' '.join(query_tokens)]).toarray()[0]\n",
    "    scores = {}\n",
    "    for idx, doc_id in enumerate(documents.keys()):\n",
    "        doc_vector = tfidf_matrix[idx].toarray()[0]\n",
    "        scores[doc_id] = cosine_similarity_score(query_vector, doc_vector)\n",
    "    ranked_results = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return ranked_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4599429-c0ee-49bc-959f-c647cbcae108",
   "metadata": {},
   "source": [
    "## 2.6. Evaluación del Sistema\n",
    "\n",
    "**Objetivo:** Medir la efectividad del sistema.\n",
    "\n",
    "**Tareas:**\n",
    "- Definir un conjunto de métricas de evaluación (precisión, recall, F1-score).\n",
    "- Realizar pruebas utilizando el conjunto de prueba del corpus.\n",
    "- Comparar el rendimiento de diferentes configuraciones del sistema.\n",
    "- Documentar los resultados y análisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46719fa0-8fc3-4e38-a3c7-9502c13758ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso\n",
    "query = \"cocoa\"\n",
    "\n",
    "# Búsqueda con Bag of Words\n",
    "results_bow = search_with_bow(query, inverted_index_bow_loaded, documentos)\n",
    "print(\"Resultados con Bag of Words:\")\n",
    "for doc_id, score in results_bow[:5]:  # Mostrar los 5 documentos más relevantes\n",
    "    print(f\"Documento: {doc_id}, Similitud Jaccard: {score}\")\n",
    "\n",
    "# Búsqueda con TF-IDF\n",
    "results_tfidf = search_with_tfidf(query, X_tfidf, vectorizer_tfidf, documentos)\n",
    "print(\"\\nResultados con TF-IDF:\")\n",
    "for doc_id, score in results_tfidf[:5]:  # Mostrar los 5 documentos más relevantes\n",
    "    print(f\"Documento: {doc_id}, Similitud Coseno: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84cdc47-0a5e-469e-92fe-08f7b64fa9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def crear_diccionario_categorias(archivo):\n",
    "    # Creamos un diccionario para almacenar las categorías y sus documentos\n",
    "    categorias = defaultdict(list)\n",
    "    with open(archivo, 'r') as file:\n",
    "        for linea in file:\n",
    "            # Separamos la línea en la ruta del documento y las categorías\n",
    "            ruta, *cats = linea.strip().split()\n",
    "            # Extraemos el número del documento de la ruta\n",
    "            numero_documento = ruta.split('/')[1]\n",
    "            # Añadimos el número del documento a cada categoría correspondiente\n",
    "            for cat in cats:\n",
    "                categorias[cat].append(numero_documento)\n",
    "\n",
    "    # Crear un diccionario de documentos a categorías (invirtiendo el anterior)\n",
    "    documentos_categorias = defaultdict(list)\n",
    "    for categoria, docs in categorias.items():\n",
    "        for doc in docs:\n",
    "            documentos_categorias[doc].append(categoria)\n",
    "\n",
    "    return documentos_categorias, list(categorias.keys())\n",
    "\n",
    "# Suponiendo que tu archivo se llama 'documentos.txt'\n",
    "archivo = 'reuters/cats.txt'\n",
    "documentos_categorias, lista_categorias = crear_diccionario_categorias(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a1f88-78b8-4909-ad5c-83ebfec9192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_etiquetas_verdaderas(documentos, query_categoria):\n",
    "    etiquetas_verdaderas = []\n",
    "    for doc_id in documentos:\n",
    "        if query_categoria in documentos_categorias[doc_id]:\n",
    "            etiquetas_verdaderas.append(0)\n",
    "        else:\n",
    "            etiquetas_verdaderas.append(1)\n",
    "    return etiquetas_verdaderas\n",
    "\n",
    "def obtener_etiquetas_predichas(resultados):\n",
    "    return [0 if score > 0 else 1 for _, score in resultados]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb4268-d5d7-401d-8612-bdefe02a97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_bow(query, query_categoria, inverted_index_bow, documentos):\n",
    "    resultados = search_with_bow(query, inverted_index_bow, documentos)\n",
    "    documentos_resultados = [doc_id for doc_id, _ in resultados]\n",
    "    etiquetas_verdaderas = obtener_etiquetas_verdaderas(documentos_resultados, query_categoria)\n",
    "    etiquetas_predichas = obtener_etiquetas_predichas(resultados)\n",
    "    return etiquetas_verdaderas, etiquetas_predichas\n",
    "\n",
    "def evaluar_tfidf(query, query_categoria, tfidf_matrix, vectorizer_tfidf, documentos):\n",
    "    resultados = search_with_tfidf(query, tfidf_matrix, vectorizer_tfidf, documentos)\n",
    "    documentos_resultados = [doc_id for doc_id, _ in resultados]\n",
    "    etiquetas_verdaderas = obtener_etiquetas_verdaderas(documentos_resultados, query_categoria)\n",
    "    etiquetas_predichas = obtener_etiquetas_predichas(resultados)\n",
    "    return etiquetas_verdaderas, etiquetas_predichas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11136276-2d58-4a29-a3d7-722be7f86171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_matriz_confusion(y_true, y_pred, categorias):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=categorias, yticklabels=categorias)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Matriz de Confusión Global')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03a4ed-2b7d-42c1-9bfb-f389611b18e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_bow = []\n",
    "y_pred_bow = []\n",
    "y_true_tfidf = []\n",
    "y_pred_tfidf = []\n",
    "\n",
    "for categoria in lista_categorias:\n",
    "    query = categoria\n",
    "    # Evaluar BOW\n",
    "    etiquetas_verdaderas_bow, etiquetas_predichas_bow = evaluar_bow(query, categoria, inverted_index_bow_loaded, documentos)\n",
    "    y_true_bow.extend(etiquetas_verdaderas_bow)\n",
    "    y_pred_bow.extend(etiquetas_predichas_bow)\n",
    "\n",
    "    # Evaluar TF-IDF\n",
    "    etiquetas_verdaderas_tfidf, etiquetas_predichas_tfidf = evaluar_tfidf(query, categoria, X_tfidf, vectorizer_tfidf, documentos)\n",
    "    y_true_tfidf.extend(etiquetas_verdaderas_tfidf)\n",
    "    y_pred_tfidf.extend(etiquetas_predichas_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74381c5c-1a3d-4447-81d6-87d27ed9615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_matriz_confusion(y_true, y_pred, categorias):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[ categorias, 'No ' +categorias], yticklabels=[ categorias, 'No ' +categorias])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Matriz de Confusión Global')\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar matriz de confusión para BOW\n",
    "mostrar_matriz_confusion(y_true_bow, y_pred_bow, 'Relevante')\n",
    "print(\"Reporte de clasificación global para Bag of Words:\")\n",
    "print(classification_report(y_true_bow, y_pred_bow, target_names=['Relevante', 'No Relevante']))\n",
    "\n",
    "# Mostrar matriz de confusión para TF-IDF\n",
    "mostrar_matriz_confusion(y_true_tfidf, y_pred_tfidf, 'Relevante')\n",
    "print(\"Reporte de clasificación global para TF-IDF:\")\n",
    "print(classification_report(y_true_tfidf, y_pred_tfidf, target_names=['Relevante', 'No Relevante']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
